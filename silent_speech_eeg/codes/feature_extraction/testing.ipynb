{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import python_speech_features\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "\n",
    "class FeaturesExtractor:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        if 'winfunc' in kwargs and kwargs['winfunc'] == 'hamming':\n",
    "            kwargs['winfunc'] = np.hamming\n",
    "        self.params = kwargs\n",
    "\n",
    "    def get_features(self, files: list) -> np.ndarray:\n",
    "        \"\"\" Extract MFCC features from the files list. \"\"\"\n",
    "        mfccs = [self.make_features(file, **self.params) for file in files]\n",
    "        X = self.align(mfccs)\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def make_features(file_path: str, **kwargs) -> np.ndarray:\n",
    "        \"\"\" Use `python_speech_features` lib to extract MFCC features from the audio file. \"\"\"\n",
    "        fs, audio = wav.read(file_path)\n",
    "        feat, energy = python_speech_features.fbank(audio, samplerate=fs, **kwargs)\n",
    "        features = np.log(feat)\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def align(arrays: list, default=0) -> np.ndarray:\n",
    "        \"\"\" Pad arrays along time dimensions. Return the single array (batch_size, time, features). \"\"\"\n",
    "        max_array = max(arrays, key=len)\n",
    "        X = np.full(shape=[len(arrays), *max_array.shape], fill_value=default, dtype=np.float64)\n",
    "        for index, array in enumerate(arrays):\n",
    "            time_dim, features_dim = array.shape\n",
    "            X[index, :time_dim] = array\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/gautam-admin/EEG/deepspeech_from_brain/data/wav/austin1.wav\"\n",
    "fs, audio = wav.read(file_path)\n",
    "feat, energy = python_speech_features.fbank(audio, samplerate=fs)\n",
    "features = np.log(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25697, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, optimizers, models\n",
    "import tcn\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9e2ec747d07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m K.get_value(K.ctc_decode(out, input_length=np.ones(out.shape[0])*out.shape[1],\n\u001b[0m\u001b[1;32m      2\u001b[0m                          greedy=True)[0][0])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "K.get_value(K.ctc_decode(out, input_length=np.ones(out.shape[0])*out.shape[1],\n",
    "                         greedy=True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f2c6ff68510>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_w = 128\n",
    "# Input Parameters\n",
    "img_h = 64\n",
    "# Network parameters\n",
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "minibatch_size = 32\n",
    "unique_tokens = 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_w, img_h)\n",
    "else:\n",
    "    input_shape = (img_w, img_h, 1)\n",
    "\n",
    "act = 'relu'\n",
    "input_data = layers.Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = layers.Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "inner = layers.MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = layers.Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv2')(inner)\n",
    "inner = layers.MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = layers.Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = layers.Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = layers.GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = layers.GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "gru1_merged = layers.add([gru_1, gru_1b])\n",
    "gru_2 = layers.GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = layers.GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = layers.Dense(unique_tokens, kernel_initializer='he_normal',\n",
    "              name='dense2')(layers.concatenate([gru_2, gru_2b]))\n",
    "y_pred = layers.Activation('softmax', name='softmax')(inner)\n",
    "keras.Model(inputs=input_data, outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activation_1', 'activation_10', 'activation_11', 'activation_12', 'activation_13', 'activation_14', 'activation_15', 'activation_16', 'activation_17', 'activation_2', 'activation_3', 'activation_4', 'activation_5', 'activation_6', 'activation_7', 'activation_8', 'activation_9', 'add_1', 'add_2', 'add_3', 'add_4', 'add_5', 'add_7', 'conv1d_1', 'conv1d_10', 'conv1d_11', 'conv1d_12', 'conv1d_13', 'conv1d_14', 'conv1d_15', 'conv1d_16', 'conv1d_17', 'conv1d_18', 'conv1d_2', 'conv1d_3', 'conv1d_4', 'conv1d_5', 'conv1d_6', 'conv1d_7', 'conv1d_8', 'conv1d_9', 'input_1', 'spatial_dropout1d_1', 'spatial_dropout1d_10', 'spatial_dropout1d_11', 'spatial_dropout1d_12', 'spatial_dropout1d_2', 'spatial_dropout1d_3', 'spatial_dropout1d_4', 'spatial_dropout1d_5', 'spatial_dropout1d_6', 'spatial_dropout1d_7', 'spatial_dropout1d_8', 'spatial_dropout1d_9', 'time_distributed_1']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('/home/gautam-admin/EEG/deepspeech_from_brain/models/model_1_100_True.hdf5', 'r')\n",
    "print(list(f.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"model_1_100_True.hdf5\" (mode r)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package h5py:\n",
      "\n",
      "NAME\n",
      "    h5py\n",
      "\n",
      "DESCRIPTION\n",
      "    This is the h5py package, a Python interface to the HDF5\n",
      "    scientific data format.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _conv\n",
      "    _errors\n",
      "    _hl (package)\n",
      "    _objects\n",
      "    _proxy\n",
      "    defs\n",
      "    h5\n",
      "    h5a\n",
      "    h5ac\n",
      "    h5d\n",
      "    h5ds\n",
      "    h5f\n",
      "    h5fd\n",
      "    h5g\n",
      "    h5i\n",
      "    h5l\n",
      "    h5o\n",
      "    h5p\n",
      "    h5py_warnings\n",
      "    h5r\n",
      "    h5s\n",
      "    h5t\n",
      "    h5z\n",
      "    highlevel\n",
      "    ipy_completer\n",
      "    tests (package)\n",
      "    utils\n",
      "    version\n",
      "\n",
      "SUBMODULES\n",
      "    filters\n",
      "\n",
      "FUNCTIONS\n",
      "    enable_ipython_completer()\n",
      "        Call this from an interactive IPython session to enable tab-completion\n",
      "        of group and attribute names.\n",
      "    \n",
      "    get_config(...)\n",
      "        () => H5PYConfig\n",
      "        \n",
      "        Get a reference to the global library configuration object.\n",
      "    \n",
      "    get_enum = py_get_enum(...)\n",
      "        (DTYPE dt_in) => DICT\n",
      "        \n",
      "        Deprecated; use check_dtype() instead.\n",
      "    \n",
      "    get_vlen = py_get_vlen(...)\n",
      "        (OBJECT dt_in) => TYPE\n",
      "        \n",
      "        Deprecated; use check_dtype() instead.\n",
      "    \n",
      "    new_enum = py_new_enum(...)\n",
      "        (DTYPE dt_in, DICT enum_vals) => DTYPE\n",
      "        \n",
      "        Deprecated; use special_dtype() instead.\n",
      "    \n",
      "    new_vlen = py_new_vlen(...)\n",
      "        (OBJECT kind) => DTYPE\n",
      "        \n",
      "        Deprecated; use special_dtype() instead.\n",
      "    \n",
      "    run_tests(verbose=False)\n",
      "        Run tests with TextTestRunner and returns a TestResult instance.\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    highlevel = <h5py.h5py_warnings.ModuleWrapper object>\n",
      "\n",
      "VERSION\n",
      "    2.9.0\n",
      "\n",
      "FILE\n",
      "    /home/gautam-admin/anaconda3/lib/python3.7/site-packages/h5py/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcn\n",
    "from tcn import TCN\n",
    "i = layers.Input(batch_shape=(None, None, 90))\n",
    "\n",
    "o = TCN(return_sequences=True)(i)  # The TCN layers are here.\n",
    "o = layers.TimeDistributed(layers.Dense(13, activation='linear'))(o)\n",
    "regressor = keras.Model(inputs=[i], outputs=[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('/home/gautam-admin/EEG/deepspeech_from_brain/models/model_1_100_True.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/activation_1\" (0 members)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
